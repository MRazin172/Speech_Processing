{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMr76afR5ypSizejqiFQOv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MRazin172/Speech_Processing/blob/main/2348534_SPR_LabProgram8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QtttwcPq6KyW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "function to initialize the Viterbi table sequence. Finding the next possible sequence and its probability."
      ],
      "metadata": {
        "id": "m7_wJBe4-p-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def viterbi_algorithm(obs, states, start_prob, trans_prob, emit_prob):\n",
        "    n_states = len(states)\n",
        "    n_obs = len(obs)\n",
        "\n",
        "    # Initialize the Viterbi table and the backpointer table\n",
        "    viterbi = np.zeros((n_states, n_obs))\n",
        "    backpointer = np.zeros((n_states, n_obs), dtype=int)\n",
        "\n",
        "    # Initialization step\n",
        "    for s in range(n_states):\n",
        "        viterbi[s, 0] = start_prob[s] * emit_prob[s][obs[0]]\n",
        "        backpointer[s, 0] = 0\n",
        "\n",
        "    # Recursion step\n",
        "    for t in range(1, n_obs):\n",
        "        for s in range(n_states):\n",
        "            prob_trans_emit = [viterbi[s_prev, t-1] * trans_prob[s_prev][s] * emit_prob[s][obs[t]] for s_prev in range(n_states)]\n",
        "            viterbi[s, t] = max(prob_trans_emit)\n",
        "            backpointer[s, t] = np.argmax(prob_trans_emit)\n",
        "    # Termination step\n",
        "    best_last_state = np.argmax(viterbi[:, -1])\n",
        "    best_prob = viterbi[best_last_state, -1]\n",
        "\n",
        "    # Backtrack to find the most probable state sequence\n",
        "    best_path = [best_last_state]\n",
        "    for t in range(n_obs-1, 0, -1):\n",
        "        best_path.insert(0, backpointer[best_path[0], t])\n",
        "\n",
        "    best_path = [states[state] for state in best_path]\n",
        "    return best_path, best_prob"
      ],
      "metadata": {
        "id": "Kfn9II8j65UH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "these are the states and observations"
      ],
      "metadata": {
        "id": "HNNik0kG7gI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "states = ['S1', 'S2', 'S3', 'S4']  # /h/, /e/, /l/, /o/\n",
        "observations = ['O1', 'O2', 'O3', 'O4']\n",
        "obs_sequence = [0, 1, 2, 3]\n"
      ],
      "metadata": {
        "id": "8N3annu768Z-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "initial transitiona and emisiion probabilities"
      ],
      "metadata": {
        "id": "29HTfV-G-4QD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_probabilities = [1.0, 0.0, 0.0, 0.0]\n",
        "\n",
        "transition_probabilities = [\n",
        "    [0.0, 0.7, 0.3, 0.0],\n",
        "    [0.0, 0.2, 0.6, 0.2],\n",
        "    [0.0, 0.0, 0.3, 0.7],\n",
        "    [0.0, 0.0, 0.1, 0.9],\n",
        "]\n",
        "\n",
        "emission_probabilities = [\n",
        "    [0.6, 0.2, 0.1, 0.1],\n",
        "    [0.1, 0.7, 0.1, 0.1],\n",
        "    [0.1, 0.1, 0.6, 0.2],\n",
        "    [0.2, 0.1, 0.2, 0.5],\n",
        "]"
      ],
      "metadata": {
        "id": "qVLhUwlQ7JSQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "running the algorithm and printing the results"
      ],
      "metadata": {
        "id": "-8R1QpOz7sjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the Viterbi algorithm\n",
        "best_path, best_prob = viterbi_algorithm(obs_sequence, states, start_probabilities, transition_probabilities, emission_probabilities)\n",
        "\n",
        "# Output the results\n",
        "print(\"Most likely phoneme sequence:\", best_path)\n",
        "print(\"Probability of the most likely sequence:\", best_prob)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4S0pJTs7JuX",
        "outputId": "38305f57-55fb-409a-c385-80816200548b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most likely phoneme sequence: ['S1', 'S2', 'S3', 'S4']\n",
            "Probability of the most likely sequence: 0.03704399999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explanation of the Code:\n",
        "1. **Initialization**:\n",
        "   - The algorithm starts by initializing the probability (`viterbi`) table using the initial probabilities and emission probabilities for the first observation.\n",
        "\n",
        "2. **Recursion**:\n",
        "   - At each time step `t`, the algorithm calculates the probabilities of reaching each state by considering all possible transitions from the previous states and incorporating the emission probabilities.\n",
        "\n",
        "3. **Termination**:\n",
        "   - The highest probability at the last observation step is identified, and backtracking is used to reconstruct the sequence of states.\n",
        "\n",
        "4. **Output**:\n",
        "   - The most likely phoneme sequence (`/h/, /e/, /l/, /o/`) and its associated probability are displayed.\n"
      ],
      "metadata": {
        "id": "lywVPteQ-Mfy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Inference\n",
        "\n",
        "The implementation of the Viterbi algorithm successfully identifies the most likely sequence of hidden phoneme states (`/h/, /e/, /l/, /o/`) for the given observation sequence `[O1, O2, O3, O4]`. This result aligns with the expected outcome, demonstrating that the algorithm effectively decodes the observation sequence based on the provided Hidden Markov Model (HMM). The probability of the most likely sequence quantifies the confidence in this prediction, validating the algorithm's utility in tasks such as speech recognition.\n",
        "\n",
        "This experiment showcases the Viterbi algorithm's ability to perform sequential decoding in an HMM context, proving its significance in recognizing words through their constituent phonemes. The methodology can be extended to larger vocabularies and more complex state-space models for real-world speech processing applications."
      ],
      "metadata": {
        "id": "YV3YrJtA-SMn"
      }
    }
  ]
}